{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yz80rPMZKObK"
   },
   "source": [
    "# Aquire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mfUX-Y7sQQV9"
   },
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kxo34j6Qdscq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('miscs/m0811/logs'):\n",
    "    os.makedirs('miscs/m0811/logs')\n",
    "if not os.path.exists('miscs/m0811/datasets'):\n",
    "    os.makedirs('miscs/m0811/datasets')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zb8ujxWx2oka",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/bash: ./download_cyclegan_dataset.sh: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in c:\\users\\lsh\\appdata\\local\\continuum\\anaconda3\\envs\\0804_gan_hw\\lib\\site-packages (1.5.1)\n",
      "Collecting torchvision==0.1.8\n",
      "  Downloading torchvision-0.1.8-py2.py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\lsh\\appdata\\local\\continuum\\anaconda3\\envs\\0804_gan_hw\\lib\\site-packages (from torchvision==0.1.8) (1.19.1)\n",
      "Requirement already satisfied: six in c:\\users\\lsh\\appdata\\local\\continuum\\anaconda3\\envs\\0804_gan_hw\\lib\\site-packages (from torchvision==0.1.8) (1.15.0)\n",
      "Collecting pillow\n",
      "  Using cached Pillow-7.2.0-cp38-cp38-win_amd64.whl (2.1 MB)\n",
      "Requirement already satisfied: torch in c:\\users\\lsh\\appdata\\local\\continuum\\anaconda3\\envs\\0804_gan_hw\\lib\\site-packages (from torchvision==0.1.8) (1.6.0)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491062 sha256=ebdf69f6048c9cf9d809a56d4170c662712b8a2121093db32763223b0b89b85a\n",
      "  Stored in directory: c:\\users\\lsh\\appdata\\local\\pip\\cache\\wheels\\8e\\70\\28\\3d6ccd6e315f65f245da085482a2e1c7d14b90b30f239e2cf4\n",
      "Successfully built future\n",
      "Installing collected packages: pillow, torchvision, future\n",
      "Successfully installed future-0.18.2 pillow-7.2.0 torchvision-0.1.8\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Horse2zebra 데이터셋 다운로드\"\"\"\n",
    "!bash miscs/m0811/download_cyclegan_dataset.sh horse2zebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZTHemRjFQQWC"
   },
   "source": [
    "# Model definition & Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aAu_qett4H4v",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional\n",
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchsummary import summary\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ufcX0A2Y4J_t"
   },
   "outputs": [],
   "source": [
    "img_size = 256 # 입력 이미지 사이즈 256x256 \n",
    "channels = 3\n",
    "ngf = 32 # G channels after first layer\n",
    "ndf = 64 # D channels after first layer\n",
    "\n",
    "epochs = 15 # 훈련 횟수, 200정도 까지 돌리면 좋으나, 시간 단축을 위해 15를 이용\n",
    "            # parameter를 바꿔 200으로 학습해서 결과를 확인할 수 있음\n",
    "batch_size = 4 # 배치 사이즈\n",
    "lambda_X = 10 # 하이퍼파라메터\n",
    "lambda_Y = 10\n",
    "lambda_identity_X = 0.5\n",
    "lambda_identity_Y = 0.5\n",
    "lr = 0.0002 # learning rate\n",
    "betas = (0.5, 0.999)\n",
    "\n",
    "mean_init = 0.0\n",
    "std_init = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "roIYTK_rvNJP",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is cpu.\n"
     ]
    }
   ],
   "source": [
    "# Cuda stuff\n",
    "device = torch.device( 'cuda' if torch.cuda.is_available() else 'cpu' )\n",
    "print(\"Device is \" + str(device) + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8M086leYqCAV"
   },
   "source": [
    "# CycleGAN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Resblock\n",
    "\n",
    "\n",
    "![Resblock](miscs/m0811/description/Resnet_block.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hPy-hIOP43Ux",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1 통과\n"
     ]
    }
   ],
   "source": [
    "# ResidualBlock 설계\n",
    "# 입력: Tensor 출력: Resnet Output\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        block = [nn.ReflectionPad2d(1),\n",
    "                 nn.Conv2d(c, c, 3, 1, 0),\n",
    "                 nn.InstanceNorm2d(c),\n",
    "                 nn.ReLU(),\n",
    "                 nn.ReflectionPad2d(1),\n",
    "                 nn.Conv2d(c, c, 3, 1, 0),\n",
    "                 nn.InstanceNorm2d(c)]\n",
    "        \n",
    "        self.block = nn.Sequential(*block)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        ###YOUR CODE HERE \n",
    "        # Forward medthod에 Residual block의 아웃풋을 채우기  \n",
    "        # Note: 위의 Description을 참조\n",
    "        \"\"\"\n",
    "    \n",
    "        return ????????????\n",
    "###Testing code ####\n",
    "test_tensor = torch.Tensor(1,3,64,64)\n",
    "R = ResidualBlock(3)\n",
    "assert(list(R(test_tensor).size()) == [1,3,64,64])\n",
    "print('test1 통과')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator\n",
    "![Generator](miscs/m0811/description/Generator.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7SijtRQW8aGv",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트2 통과\n"
     ]
    }
   ],
   "source": [
    "# Generator 설계\n",
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()\n",
    "        \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # Encoding\n",
    "        model = []\n",
    "        model += [nn.ReflectionPad2d(4),\n",
    "                  nn.Conv2d(3, ngf, 9, 1, 0),\n",
    "                  nn.InstanceNorm2d(ngf),\n",
    "                  nn.ReLU()]\n",
    "        model += [nn.Conv2d(ngf, ngf*2, 4, 2, 1),\n",
    "                  nn.InstanceNorm2d(ngf*2),\n",
    "                  nn.ReLU()]\n",
    "        model += [nn.Conv2d(ngf*2, ngf*4, 4, 2, 1),\n",
    "                  nn.InstanceNorm2d(ngf*4),\n",
    "                  nn.ReLU()]\n",
    "        \n",
    "        # Transformation\n",
    "        \"\"\"\n",
    "        ### YOUR CODE HERE \n",
    "        # 아래 물음표 친 곳의 코드를 채우시오\n",
    "        # 1. Generator에 Residual block 을 채우기\n",
    "        # 2. Decoding의 차원을 잘 맞춰서 원래 이미지 사이즈로 복원하기 ==> \n",
    "        # Note: 1. https://pytorch.org/docs/master/generated/torch.nn.ConvTranspose2d.html에서 output shape 확인하고 채우기 \n",
    "                2. 매번 줄어든 이미지를 다시 2배씩 키우고 채널수를 2배 줄이기\n",
    "        \"\"\"\n",
    "        for i in range(6):\n",
    "            model += [????????????(ngf*4)]   # 채널 수를 그대로 유지하면서 반복시켜주는 Residual block\n",
    "        \n",
    "        # Decoding\n",
    "        model += [nn.ConvTranspose2d(ngf*4, ngf*2, kernel_size =?, stride =?, padding = ?, output_padding=?), # 줄여준 H * W 를 다시 반대로 늘려주는 과정\n",
    "                  nn.InstanceNorm2d(ngf*2),\n",
    "                  nn.ReLU()]\n",
    "\n",
    "        model += [nn.ConvTranspose2d(ngf*2, ngf, kernel_size =?, stride =?, padding = ?, output_padding=?),\n",
    "                  nn.InstanceNorm2d(ngf),\n",
    "                  nn.ReLU()]\n",
    "\n",
    "        model += [nn.ReflectionPad2d(4),\n",
    "                  nn.Conv2d(ngf, 3, 9, 1, 0),\n",
    "                  nn.Tanh()]\n",
    "        \n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "### Testing code\n",
    "test_tensor = torch.Tensor(1,3,256,256)\n",
    "G= Generator()\n",
    "assert(list(G(test_tensor).size()) ==[1,3,256,256])\n",
    "print('테스트2 통과')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator\n",
    "![Discriminator](miscs/m0811/description/Discriminator.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ScqGWgOGTCnx",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트3 통과\n"
     ]
    }
   ],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \"\"\"\n",
    "        ### YOUR CODE HERE \n",
    "        # 아래 물음표 친 곳의 코드를 채우시오\n",
    "        # 1. Input, Output channel 의 사이즈를 위 그림에 맞게 넣기\n",
    "        # 2. Decoding의 차원을 잘 맞춰서 원래 이미지 사이즈로 복원하기 ==> \n",
    "        \"\"\"\n",
    "        \n",
    "        model = []\n",
    "        model += [nn.Conv2d(3, ??, ??, ??, ??),   # outputchannel : ndf, kernel: 4, stride:2 , padding : 1\n",
    "                  nn.LeakyReLU(0.2)]\n",
    "        \n",
    "        in_channels = ndf\n",
    "        out_channels = ndf*2\n",
    "        \n",
    "        for i in range(2):\n",
    "            model += [nn.Conv2d(???????????, ??????????, 4, 2, 1),     # 어떤 변수가 input channel이 되고, 어떤 변수가 output channel이 되는가?\n",
    "                      nn.InstanceNorm2d(out_channels),\n",
    "                      nn.LeakyReLU(0.2)]\n",
    "            # 매 반복마다 channel 수가 두배가 되도록 하려면?\n",
    "\n",
    "            in_channels = ???????????????           \n",
    "            out_channels = ???????????????\n",
    "\n",
    "        model += [nn.Conv2d(in_channels, out_channels, 4, 1, 1),\n",
    "                  nn.InstanceNorm2d(out_channels),\n",
    "                  nn.LeakyReLU(0.2)]\n",
    "        \n",
    "        model += [nn.Conv2d(out_channels, 1, 4, 1, 1)]\n",
    "        \n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "### Testing code\n",
    "test_tensor = torch.Tensor(1,3,256,256)\n",
    "D= Discriminator()\n",
    "assert(list(D(test_tensor).size()) ==[1,1,30,30])\n",
    "print('테스트3 통과')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oUHQaDB95Kip"
   },
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AQZCce-PjX3Z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset Code\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "class UnallignedDataset(Dataset):\n",
    "    def __init__(self, root, transform, phase='train'):\n",
    "        dir_A = os.path.join(root, phase + 'A')\n",
    "        dir_B = os.path.join(root, phase + 'B')\n",
    "        \n",
    "        self.A_paths = [os.path.join(dir_A, f) for f in os.listdir(dir_A)]\n",
    "        self.B_paths = [os.path.join(dir_B, f) for f in os.listdir(dir_B)]\n",
    "        self.A_size = len(self.A_paths)\n",
    "        self.B_size = len(self.B_paths)\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        A_path = self.A_paths[index % self.A_size]\n",
    "        B_path = self.B_paths[random.randint(0, self.B_size - 1)]\n",
    "        \n",
    "        A_img = Image.open(A_path).convert('RGB')\n",
    "        B_img = Image.open(B_path).convert('RGB')\n",
    "\n",
    "        A = self.transform(A_img)\n",
    "        B = self.transform(B_img)\n",
    "        return A, B\n",
    "    \n",
    "    def __len__(self):\n",
    "        return max(self.A_size, self.B_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pHht4nVj8n7F"
   },
   "outputs": [],
   "source": [
    "# 학습을 돕기 위한 추가 테크닉 (과제를 위해 알아야할 필요는 없음) (참고: https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/issues/75)\n",
    "\n",
    "class ImagePool():\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "        self.images = []\n",
    "        \n",
    "    def get(self, img):\n",
    "        if len(self.images) < self.pool_size:\n",
    "            self.images.append(img)\n",
    "            return img\n",
    "        else:\n",
    "            p = random.random()\n",
    "            if p > 0.5:\n",
    "                idx = random.randint(0, self.pool_size-1)\n",
    "                tmp = self.images[idx]\n",
    "                self.images[idx] = img\n",
    "                return tmp\n",
    "            else:\n",
    "                return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1_nWsNBQKhGz"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "il5CP_fDXnay",
    "tags": []
   },
   "outputs": [],
   "source": [
    "G = Generator().to(device)\n",
    "F = Generator().to(device)\n",
    "D_X = Discriminator().to(device)\n",
    "D_Y = Discriminator().to(device)\n",
    "G.weight_init(mean_init, std_init)\n",
    "F.weight_init(mean_init, std_init)\n",
    "D_X.weight_init(mean_init, std_init)\n",
    "D_Y.weight_init(mean_init, std_init)\n",
    "G.train()\n",
    "F.train()\n",
    "D_X.train()\n",
    "D_Y.train()\n",
    "shuffle=False\n",
    "\n",
    "\"\"\"\n",
    "### YOUR CODE HERE \n",
    "# 아래 물음표 친 곳의 코드를 채우시오\n",
    "# torch.utils.data.DataLoader 의 data를 불러오는 방식을 random으로 설정\n",
    "# Note: https://pytorch.org/docs/stable/data.html 참조\n",
    "\"\"\"\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize(img_size), transforms.CenterCrop(img_size), transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
    "train_loader = torch.utils.data.DataLoader(dataset=UnallignedDataset('miscs/m0811/datasets/horse2zebra', transform), \n",
    "                                           batch_size=batch_size, \n",
    "                                           ???????????, \n",
    "                                           pin_memory=True, \n",
    "                                           num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=UnallignedDataset('miscs/m0811/datasets/horse2zebra', transform, phase='test'), \n",
    "                                           batch_size=batch_size, \n",
    "                                           ???????????, \n",
    "                                           pin_memory=True, \n",
    "                                           num_workers=2)\n",
    "\n",
    "X_pool = ImagePool(50)\n",
    "Y_pool = ImagePool(50)\n",
    "\n",
    "mse_criterion = nn.MSELoss()\n",
    "l1_criterion = nn.L1Loss()\n",
    "\n",
    "GF_optimizer = torch.optim.Adam(list(G.parameters()) + list(F.parameters()), lr=lr, betas=betas)\n",
    "D_X_optimizer = torch.optim.Adam(D_X.parameters(), lr=lr, betas=betas)\n",
    "D_Y_optimizer = torch.optim.Adam(D_Y.parameters(), lr=lr, betas=betas)\n",
    "\n",
    "GF_scheduler = StepLR(GF_optimizer, 1, lr/100.0)\n",
    "D_X_scheduler = StepLR(D_X_optimizer, 1, lr/100.0)\n",
    "D_Y_scheduler = StepLR(D_Y_optimizer, 1, lr/100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(G, (3, 256, 256))\n",
    "summary(D_X, (3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(lst):\n",
    "    return sum(lst)/len(lst)\n",
    "\n",
    "# Prepare some test data, 5 of each kind\n",
    "test_data = [(x.to(device), y.to(device)) for i, (x, y) in enumerate(test_loader) if i<5]\n",
    "\n",
    "# Define target vectors\n",
    "fake_target = 0.0\n",
    "real_target = 1.0\n",
    "for epoch in range(epochs):\n",
    "    G_gan_loss_epoch = []\n",
    "    G_cycle_loss_epoch = []\n",
    "    G_ident_loss_epoch = []\n",
    "    D_X_gan_loss_epoch = []\n",
    "    \n",
    "    # Linear lr decay\n",
    "    if epoch > 99:\n",
    "        GF_scheduler.step()\n",
    "        D_X_scheduler.step()\n",
    "        D_Y_scheduler.step()\n",
    "        \n",
    "    for i, (X, Y) in enumerate(train_loader):\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        #########################################################\n",
    "        # Update generators\n",
    "        #########################################################\n",
    "        GF_optimizer.zero_grad()\n",
    "        \n",
    "        # Translate from X to Y, check D_Y output\n",
    "        G_out = G(X)\n",
    "        D_Y_out = D_Y(G_out)\n",
    "        G_gan_loss = mse_criterion(D_Y_out, torch.ones_like(D_Y_out).to(device))\n",
    "        \n",
    "        # Translate from Y to X, check D_X output\n",
    "        F_out = F(Y)\n",
    "        D_X_out = D_X(F_out)\n",
    "        F_gan_loss = mse_criterion(D_X_out, torch.ones_like(D_X_out).to(device))\n",
    "        \n",
    "        # Translate from X to Y to X, check reconstruction error\n",
    "        X_recon = F(G_out)\n",
    "        G_cycle_loss = l1_criterion(X_recon, X) * lambda_X\n",
    "        \n",
    "        # Translate from Y to X to Y, check reconstruction error\n",
    "        Y_recon = G(F_out)\n",
    "        F_cycle_loss = l1_criterion(Y_recon, Y) * lambda_Y\n",
    "        \n",
    "        # Translate a picture from Y from X to Y, should be Y\n",
    "        Y_ident = G(Y)\n",
    "        G_ident_loss = l1_criterion(Y_ident, Y) * lambda_identity_X * lambda_X\n",
    "        \n",
    "        # Translate a picture from X from Y to X, should be X\n",
    "        X_ident = F(X)\n",
    "        F_ident_loss = l1_criterion(X_ident, X) * lambda_identity_X * lambda_Y\n",
    "        \"\"\"\n",
    "        ### YOUR CODE HERE \n",
    "        # 아래 물음표 친 곳의 코드를 채우시오\n",
    "        # 1. Generator loss를 완성하시오\n",
    "        # 2. Discriminator의 loss를 완성하시오\n",
    "        # 3. loss와 optimizer의 update를 완성하시오\n",
    "        # Note: https://pytorch.org/docs/stable/data.html 참조\n",
    "        \"\"\"\n",
    "        GF_loss = G_cycle_loss + ?????????? + G_ident_loss + ???????????? + G_gan_loss + ??????????? \n",
    "        GF_loss.backward()\n",
    "        GF_optimizer.step()\n",
    "        \n",
    "        #########################################################\n",
    "        # Update discriminators\n",
    "        # D_Y, minimize L_D_Y = E_y (D(y) - 1) ^2 + E_x (D(x))^2\n",
    "        #########################################################\n",
    "        D_Y_optimizer.zero_grad()\n",
    "        \n",
    "        # Test D_Y with fake and real input\n",
    "        G_out = Y_pool.get(G_out)\n",
    "        D_Y_out_fake = D_Y(G_out.detach())\n",
    "        D_Y_out_real = D_Y(Y)\n",
    "        # Calculate loss\n",
    "        D_Y_loss_fake = mse_criterion(D_Y_out_fake, torch.zeros_like(D_Y_out_fake).to(device))\n",
    "        D_Y_loss_real = mse_criterion(D_Y_out_real, torch.ones_like(D_Y_out_real).to(device))\n",
    "        D_Y_gan_loss = (D_Y_loss_real + D_Y_loss_fake)*0.5        \n",
    "        \n",
    "        D_Y_gan_loss.???????? # back propagation 해주기\n",
    "        D_Y_optimizer.?????? # optimizer가 한 스텝 나아가기\n",
    "        \n",
    "        #########################################################\n",
    "        # D_X, minimize L_D_X = E_x (D(x) - 1) ^2 + E_y (D(y))^2\n",
    "        #########################################################\n",
    "        D_X_optimizer.zero_grad()\n",
    "        \n",
    "        # Test D_X with fake and real input\n",
    "        F_out = X_pool.get(F_out)\n",
    "        D_X_out_fake = D_X(F_out.detach())\n",
    "        D_X_out_real = D_X(X)\n",
    "        # Calculate loss\n",
    "        D_X_loss_fake = mse_criterion(D_X_out_fake, torch.zeros_like(D_X_out_fake).to(device))\n",
    "        D_X_loss_real = mse_criterion(D_X_out_real, torch.ones_like(D_X_out_real).to(device))\n",
    "        D_X_gan_loss = (D_X_loss_real + D_X_loss_fake)*0.5\n",
    "\n",
    "        D_X_gan_loss.???????? # back propagation 해주기\n",
    "        D_X_optimizer.?????? # optimizer가 한 스텝 나아가기\n",
    "                \n",
    "        # Save losses\n",
    "        G_gan_loss_epoch.append(G_gan_loss.item())\n",
    "        G_cycle_loss_epoch.append(G_cycle_loss.item())\n",
    "        G_ident_loss_epoch.append(G_ident_loss.item())\n",
    "        D_X_gan_loss_epoch.append(D_X_gan_loss.item())\n",
    "        \n",
    "        # Do some test output every 100 batches\n",
    "        if i % 100 == 0:\n",
    "            checkname = 'Epoch [%d/%d], Batch [%d/%d]' % (epoch+1, epochs, i, len(train_loader))\n",
    "            savename = 'miscs/m0811/logs/Epoch%dBatch%d' % (epoch+1, i)\n",
    "            print(checkname)\n",
    "            \n",
    "            image_tensor = None\n",
    "            # Generate test outputs\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                G.eval()\n",
    "                F.eval()\n",
    "                for X, Y in test_data:\n",
    "                    G_out = G(X)\n",
    "                    F_out = F(Y)\n",
    "                    if image_tensor is None:\n",
    "                        image_tensor = torch.cat((X, G_out, Y, F_out), 0)\n",
    "                    else:\n",
    "                        image_tensor = torch.cat((image_tensor, X, G_out, Y, F_out), 0)\n",
    "                G.train()\n",
    "                F.train()\n",
    "            save_image(image_tensor, savename + '.png', nrow=4, padding=50)\n",
    "            \n",
    "#             save_image(image_tensor, './i.' nrow=4, padding=2, normalize=True)\n",
    "#             writer.add_image('test_images', image, i+epoch*len(train_loader))\n",
    "    \n",
    "    # Calculate mean\n",
    "    G_gan_loss_epoch = mean(G_gan_loss_epoch)\n",
    "    G_cycle_loss_epoch = mean(G_cycle_loss_epoch)\n",
    "    G_ident_loss_epoch = mean(G_ident_loss_epoch)\n",
    "    G_loss_epoch = G_gan_loss_epoch + G_cycle_loss_epoch + G_ident_loss_epoch\n",
    "    D_X_gan_loss_epoch = mean(D_X_gan_loss_epoch)\n",
    "  \n",
    "print('학습 완료')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JQ2CQ5KnQQWX"
   },
   "outputs": [],
   "source": [
    "# 학습된 parameter 저장하기\n",
    "torch.save(G.state_dict(), 'miscs/m0811/G.pt')\n",
    "torch.save(F.state_dict(), 'miscs/m0811/F.pt')\n",
    "torch.save(D_X.state_dict(), 'miscs/m0811/D_X.pt')\n",
    "torch.save(D_Y.state_dict(), 'miscs/m0811/D_Y.pt')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cyclegan_horse2zebra_assign.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
